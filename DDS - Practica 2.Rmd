---
title: "DDS - Práctica 2"
output:
  html_document: default
  pdf_document: default
date: "2024-01-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Driven Security - Actividad Evaluable 2

## Víctor López García & Lucas Carrillo Mas

### 1. Datos Elegantes + Análisis de Datos con Web Scrapping

Se listarán a continuación los enunciados de las preguntas requeridas junto con su respuesta.

#### Pregunta 1 - Queremos programar un programa de tipo web scrapping con el que podamos obtener una página web, mediante su URL, y poder analizar su contenido HTML con tal de extraer datos e información específica. Nuestro programa ha de ser capaz de cumplir con los pasos especificados en el pdf de la práctica. Se detalla cada uno con su código a continuación:


##### 1. Descargar la página web de la URL indicada, y almacenarlo en un formato de R apto para ser tratado.


```{r carga paquetes}
library(httr)
library(xml2)
library(XML)
library(rvest)
library(tidyverse)
library(ggplot2)
```


```{r descarga web}
descarga_web <- GET(url="https://www.mediawiki.org/wiki/MediaWiki")

contenido_web <- content(descarga_web, encoding="UTF-8")

# Lo almaceno en un fichero apto para ser tratado con R --> parseo a XML

contenido_xml <- htmlParse(contenido_web, asText=TRUE)
```

Otra forma más sencilla y con la que continuaremos a lo largo de la práctica, es utilizando la librería "rvest".

```{r descarga web fácil}
contenido_xml <- read_html("https://www.mediawiki.org/wiki/MediaWiki") # Contenido en xml

```

##### 2. Analizar el contenido de la web, buscando el título de la página (que en HTML se etiqueta como “title”).


```{r titulo}
titulo <- html_elements(contenido_xml, "title") %>% html_text()
```

##### 3. Analizar el contenido de la web, buscando todos los enlaces (que en HTML se etiquetan como “a”), buscando el texto del enlace, así como la URL.


```{r enlaces}
links <- html_elements(contenido_xml, "a") %>% html_attr("href")
texto_links <- html_elements(contenido_xml, "a") %>% html_text()
```

Vemos que existen entradas vacías en "texto_links", que podemos verificar que corresponden a botones en la web (que no tienen texto).

##### 4. Generar una tabla con cada enlace encontrado, indicando el texto que acompaña el enlace, y el número de veces que aparece un enlace con ese mismo objetivo.

Vamos a generar una columna que combine la de links y la del texto y contar el número de veces que aparece el mismo link con el mismo texto en la web.

```{r recuento}
df_links <- data.frame(links, texto_links)
#head(df_links)

# Añadir columna que hace una tupla de la columna 1 y la 2 porque quiero contar cuántas veces se repite el mismo link con el mismo texto

df_links$combinado <- paste(df_links$links, df_links$texto_links, sep = " - ")

df_links <- df_links %>%
  mutate(
    links = as.factor(links),
    texto_links = as.factor(texto_links)
  )

tabla_links <- table(df_links$combinado)
#head(tabla_links)
view(df_links)
view(tabla_links)
```


##### 5. Para cada enlace, seguirlo e indicar si está activo (podemos usar el código de status HTTP al hacer una petición a esa URL).

```{r status}

# Lo paso a string otra vez pra trabajar con ella

df_links <- df_links %>%
  mutate(
    links = as.character(links),
    texto_links = as.factor(texto_links)
  )

filtro_abs <- substr(df_links$links, 1,4) == "http" | substr(df_links$links, 1,2) == "//"

frec_absol <- table(df_links[filtro_abs, "links"])
status_absolute <- c()

for (x in 1:length(frec_absol)) {
  string <- names(frec_absol)[x]
  ifelse(substr(string, 1,2)=="//", string <- paste("https:", string, sep=""), 1)
  status_absolute <- c(status_absolute, HEAD(string)$status_code)
  Sys.sleep(0.1)
}

frec_relat <- table(df_links[!filtro_abs, "links"])
status_relative <- c()

for (x in 1:length(frec_relat)) {
  string <- paste("https://www.mediawiki.org/", names(frec_relat)[x], sep="")
  status_relative <- c(status_relative, HEAD(string)$status_code)
  Sys.sleep(0.1)
}

# Ahora vamos a representarlo de la forma que se nos pide



```


#### Pregunta 2 - Elaborad, usando las librerías de gráficos base y qplot (ggplot2), una infografía sobre los datos obtenidos. Tal infografía será una reunión de gráficos donde se muestren los siguientes detalles:


##### 1. Un histograma con la frecuencia de aparición de los enlaces, pero separado por URLs absolutas (con “http…”) y URLs relativas.

En primer lugar, construimos el gráfico de barras que se nos pide en el enunciado, pero vemos que nos aporta poca información a nivel de análisis de nuestra base de datos, ya que la mayor parte de los enlaces aparecen una única vez. Vamos entonces a aislar todas estas observaciones que son únicas y presentarlas en la tabla "df_links_unicos". Se representa entonces el gráfico de barras de las urls que aparecen en más de una observación.

```{r histograma}
# Crear una nueva columna para indicar si el enlace es absoluto o relativo
df_links$tipo_enlace <- ifelse(grepl("^http", df_links$links) | grepl("^//", df_links$links), "Absoluto", "Relativo")

# Tengo en cuenta que hay urls absolutas que empiezan por http o por // (que serían absolutas también aunque no lo dice el enunciado) 

frec_links <- table(df_links$links)
df_frec_links <- as.data.frame(frec_links)

df_frec_links_sin1 <- subset(df_frec_links, Freq != 1)
df_links_unicos <- subset(df_frec_links, Freq == 1)
View(df_links_unicos)

# Asigno colores condicionales
colores <- ifelse(df_links$tipo_enlace == "Absoluto", "blue", "red")

# Crear un histograma con colores condicionales
grafico_barras <- barplot(df_frec_links_sin1$Freq,
                   col = colores,
                   xlab = "Enlaces",
                   main = "Frecuencia de enlaces")

# Añadir leyenda manualmente
legend("topright", legend = c("Absoluto", "Relativo"),
       fill = c("blue", "red"))

# Rotar etiquetas del eje x para leer mejor
par(mar = c(7, 4, 4, 2) + 0.1)
#axis(1, at = 1:length(df_links$links), labels = df_links$links, las = 2, cex.axis = 0.6)

# Definir etiquetas personalizadas (A, B, C, ...)
etiquetas_letras <- LETTERS[1:length(df_frec_links_sin1$Freq)]

# Añadir etiquetas al eje 
axis(1, at = grafico_barras, labels = etiquetas, las = 1, cex.axis = 1, padj = -0.5)


```
Notar que se representan los links con las letras A hasta J para dar un aspecto más limpio al gráfico, la leyenda para saber qué url corresponde a cada letra en el gráfico se deja a continuación:

```{r leyenda urls grafico}

df_frec_links_sin1$EtiquetaGrafico <- LETTERS[1:length(df_frec_links_sin1$Freq)]
view(df_frec_links_sin1)
```

##### 2. Un gráfico de barras indicando la suma de enlaces que apuntan a otros dominios o servicios (distinto a https://www.mediawiki.org en el caso de ejemplo) vs. la suma de los otros enlaces.


##### 3. Un gráfico de tarta (pie chart) indicando los porcentajes de Status de nuestro análisis.

```{r pie chart}
# Creo columna pasando todos los 
# Calculo porcentajes de aparición de cada status
porcentajes <- prop.table(table(df_links$status)) * 100

# Crear el pie chart
ggplot(data = NULL, aes(x = "", y = porcentajes, fill = factor(names(porcentajes)))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  theme_void() +
  scale_fill_manual(values = c("blue", "red", "green")) +  # Puedes ajustar los colores aquí
  ggtitle("Porcentaje de Aparición de Status")

```







### 2. Análisis de logs de servidor usando R (parte II)






### 3. Clústering de datos

